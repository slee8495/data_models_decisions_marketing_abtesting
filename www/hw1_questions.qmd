---
title: "A Replication of Karlan and List (2007)"
author: "Sangho Lee"
date: today
format: html
engines:
  - r
  - python
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---

## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the *American Economic Review* in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

*What kind of problem are we solving, what is the story?* - I am addressing a field experiment evaluation problem focused on determining the effectiveness of different fundraising approaches in increasing donation rates. This study forms part of a project for the UC San Diego, MSBA program; MGTA 495 - Marketing Analytics course.

*What is the goal of the analysis?* - The goal of the analysis is to develop a statistical model to compare the success rates of the three different types of fundraising letters. The model will evaluate which approach is most effective in generating donations and will provide insights into how variations in message framing can impact donor behavior. Ultimately, this analysis will help guide fundraising strategies by identifying the most effective methods for soliciting donations, thus enabling more efficient and targeted fundraising campaigns.

<br>

## Data

### Description

#### I will now load the data and preview the first few rows. Since the data is in .dta format, I'm going to use the haven package to import it into this environment. Then, I will display the top 10 rows as a sample.

```{r, include = FALSE}
if (!"reticulate" %in% installed.packages()) {
  install.packages("reticulate")
}

```

```{r, warning=FALSE, message=FALSE}
library(haven)
library(tidyverse)
library(magrittr)
library(scales)
library(data.table)
library(reticulate)

```

```{r, warning=FALSE, message=FALSE}
data <- haven::read_dta("karlan_list_2007.dta")

# Create a table
data %>% 
  head(10) %>% 
  knitr::kable() 

```

<br>

#### I am also going to load the Python packages that I will need to complete the work in this environment.

```{python}
import pandas as pd
import numpy as np
import pyrsm as rsm
import matplotlib.pyplot as plt
import statsmodels.api as sm


```

```{python, include = FALSE}
data = pd.read_stata("karlan_list_2007.dta")

```

::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|-------------------|-----------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |
:::

<br>

### Balance Test

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

#### I'm going to conduct t-tests and linear regressions on several variables, such as months since last donation, to determine if there are statistically significant differences between the treatment and control groups at the 95% confidence level. For the t-tests, I will use the t.test function in R to analyze the data. For the linear regressions, I will utilize the pyrsm package in Python to examine the impact of the treatment by regressing variables like months since last donation against the treatment group and observing the coefficient of the treatment variable. This approach will allow me to confirm that both methods yield consistent results.

1.  mrm2 variable

```{r}
t.test(mrm2 ~ treatment, data = data, conf.level = 0.95)

```

```{python}

lm = rsm.model.regress(
  data = data,
  rvar = "mrm2",
  evar = "treatment"
)

lm.summary()
```

-   P-value: Both methods yield a p-value of approximately 0.905
-   Interpretation: There are no significant differences between the treatment and control groups for "mrm2" (months since last donation). This suggests effective randomization, indicating that any observed treatment effects are likely due to the treatment itself rather than pre-existing group differences.

<br>

2.  pwhite variable

```{r}
t.test(pwhite ~ treatment, data = data, conf.level = 0.95)

```

```{python}

lm = rsm.model.regress(
  data = data,
  rvar = "pwhite",
  evar = "treatment"
)

lm.summary()
```

-   P-value: Both the t-test and linear regression show a p-value around 0.575.
-   Interpretation: There is no significant difference in the proportion of white individuals between the treatment and control groups, indicating that the randomization was successful in creating comparable groups regarding racial composition.

<br>

3.  female variable

```{r}
t.test(female ~ treatment, data = data, conf.level = 0.95)

```

```{python}

lm = rsm.model.regress(
  data = data,
  rvar = "female",
  evar = "treatment"
)

lm.summary()
```

-   P-value: The t-test has a p-value of 0.07952 and the linear regression also shows a p-value of 0.079.
-   Interpretation: The results suggest a marginal difference in the proportion of females between the treatment and control groups that approaches but does not reach conventional levels of statistical significance (p \< 0.05).

##### Understanding the T-value and P-value

-   T-value (1.7535): The t-value measures the ratio of the difference between the group means to the standard error of the difference. A t-value of 1.7535 indicates that the difference between the group means (for the proportion of females in treatment versus control) is 1.7535 times the standard error away from zero. The sign (+) of the t-value suggests that the mean proportion of females in the treatment group is slightly lower than in the control group, given the negative coefficient in the regression output.

-   P-value (0.07952): The p-value tells us the probability of observing a t-value as extreme as 1.7535 (or more) if the null hypothesis were true which was there is no difference in the proportion of females between groups.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation.

#### I'm going to create a bar plot that visualizes the proportion of people who donated, with two separate bars representing the treatment and control groups. This will allow for a clear comparison of the donation rates between the two groups

```{r}
plot_data <- data %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(Proportion_Donated = mean(gave == 1, na.rm = TRUE)) %>%
  dplyr::mutate(Group = ifelse(treatment == 1, "Treatment", "Control")) %>%
  dplyr::select(Group, Proportion_Donated)

ggplot2::ggplot(plot_data, aes(x = Group, y = Proportion_Donated, fill = Group)) +
  ggplot2::geom_bar(stat = "identity", position = "dodge", width = 0.5) +
  ggplot2::geom_text(aes(label=scales::percent(Proportion_Donated)), vjust=-0.3, size=5) +
  ggplot2::scale_y_continuous(labels = scales::percent_format()) +
  ggplot2::labs(y = "Proportion of Donations", title = "Proportion of People Who Donated by Group") +
  ggplot2::theme_classic() +
  ggplot2::theme(
    plot.title = element_text(hjust = 0.5, size = 22),
    axis.title.y = element_text(size = 20),
    axis.text.x = element_text(size = 20),
    axis.title.x = element_blank(),
    legend.position = "none"
  ) +
  ggplot2::scale_fill_manual(values = c("Treatment" = "#FF5733", "Control" = "#33C1FF"))

```

#### I'm going to perform a t-test to compare the treatment and control groups based on whether a charitable donation was made. Additionally, I will conduct a linear regression to analyze the same data. After obtaining the statistical outcomes, I will interpret these results in the context of the experiment. Specifically, if the results show a statistically significant difference, I'll discuss what these findings suggest about human behavior towards charitable giving, focusing more on qualitative insights rather than numerical data.

```{r}
t.test(gave ~ treatment, data = data, var.equal = FALSE)

```

```{python}

lm = rsm.model.regress(
  data = data,
  rvar = "gave",
  evar = "treatment"
)

lm.summary()
```

#### The t-test and linear regression both show that the treatment group had a slightly higher donation rate (2.2%) compared to the control group (1.8%). This statistically significant difference (p-value = 0.0013 for the t-test) suggests that even a modest intervention can effectively increase the likelihood of donating. This demonstrates how small nudges, such as targeted reminders, can influence human behavior and enhance donation rates, which is crucial for organizations aiming to improve their fundraising outcomes.

<br>

#### I'm going to conduct a probit regression where the outcome variable is whether a charitable donation was made, and the explanatory variable is whether individuals were assigned to the treatment or control group.

```{python}
# Create the dependent and independent variables
X = data[['treatment']]  
X = sm.add_constant(X)  
y = data['gave']  

# Fit a probit model
probit_model = sm.Probit(y, X).fit()
print(probit_model.summary())
```

<br>

-   Probit Regression Explained: Probit regression is a type of regression used in statistics to analyze binary (two outcome) variables. In this context, it models the probability that someone made a charitable donation based on whether they were in the treatment group or not.

Key Elements of the Output:

-   Dependent Variable (gave): This is what we're trying to predict: whether or not someone gave a donation (1 if yes, 0 if no).

-   Number of Observations (50,083): This is the total number of data points used in the model.

-   Model (Probit): The type of model used, which in this case uses a Probit link function. This function maps any input from minus infinity to infinity to a 0 to 1 range, fitting the binary nature of the dependent variable.

-   MLE (Maximum Likelihood Estimation): This is the method used to fit the model, optimizing to find the parameter values that maximize the likelihood of the data given the model.

-   Coefficients:

1.  const (-2.1001): This is the intercept, or baseline log odds of donating when all predictors are 0 (i.e., not in the treatment group). A negative value indicates a low baseline probability of donation.
2.  treatment (0.0868): This coefficient shows the effect of being in the treatment group. It suggests that being in the treatment group increases the likelihood of donating compared to the control group.

-   Standard Error (std err): These values (0.023 for const and 0.028 for treatment) measure the average distance that the estimated values (coefficients) fall from the actual value. Smaller standard errors suggest more precise estimates.

-   Z-value: This is the test statistic used to determine whether to reject the null hypothesis (that the coefficient is zero, implying no effect). For the treatment, a z-value of 3.113 indicates a statistically significant effect.

-   P-value: For treatment (0.002), this value is very small, indicating strong evidence against the null hypothesis. It suggests that the treatment effect is statistically significant and not due to random chance.

-   Confidence Interval: For treatment (\[0.032, 0.141\]), this range gives us a 95% confidence level that the true coefficient falls within this interval. It confirms that the effect is positive and fairly precise.

<br><br>

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

#### Now, I will perform a series of t-tests to evaluate whether different match ratios influence the likelihood of making a donation. Specifically, I'll compare the donation rates under a 2:1 match ratio to those under a 1:1 match ratio.

```{r}
group_1_1 <- data[data$ratio == 1, "gave"] 
group_2_1 <- data[data$ratio2 == 1, "gave"] 

# T-test between 1:1 match rate and 2:1 match rate
t_test_1_1_vs_2_1 <- t.test(group_1_1, group_2_1, alternative = "two.sided", var.equal = TRUE)

t_test_1_1_vs_2_1


```

### Interpretation:

- T-value Interpretation: In this context, a t-value of -0.96505 indicates a relatively small difference in donation rates between the two match ratios, which is not statistically significant. 

- P-value Interpretation: The p-value of 0.3345 indicates that there is not a statistically significant difference between the donation rates of the 1:1 and 2:1 match ratios at the conventional 0.05 significance level. This means that the null hypothesis (that there is no difference in means) cannot be rejected based on the data provided.

- Mean Donation Rates: The mean donation rate for the 1:1 match ratio group (mean of x) is approximately 2.07%, and for the 2:1 match ratio group (mean of y), it's approximately 2.26%. Although the 2:1 match ratio shows a higher mean donation rate, the difference is not statistically significant based on the t-test results.

- Confidence Interval: The confidence interval ranges from about -0.57% to +0.19%. Since this interval includes zero, it further supports the conclusion that we cannot assert a significant difference in donation rates between these two groups. The interval suggests that the true difference could range from a slight decrease to a slight increase when moving from a 1:1 to a 2:1 match.

- Conclusion: The analysis does not provide evidence that increasing the match ratio from 1:1 to 2:1 significantly increases the likelihood that someone donates. 

<br><br>


#### Now, I'm going to analyze the impact of different match ratios on the likelihood of donations using regression analysis. I'll create a variable called ratio1 and then regress the binary outcome gave on ratio1, ratio2, and ratio3. Alternatively, I could use a single categorical variable ratio to perform the regression. After obtaining the regression coefficients, I will interpret their significance and statistical precision to understand the influence of match ratios on donation behavior.

*Data Preparation*

```{r, include=FALSE}
data <- data %>%
  mutate(
    ratio1 = case_when(
      ratio == 1 ~ "1:1",
      ratio2 == 1 ~ "2:1",
      ratio3 == 1 ~ "3:1",
      TRUE ~ "No Match" 
    ),
    ratio1 = factor(ratio1)  
  )

```




```{python}
# Define a function that applies the conditions to create the new `ratio1` values
def calculate_ratio1(row):
    if row['ratio'] == 1:
        return "1:1"
    elif row['ratio2'] == 1:
        return "2:1"
    elif row['ratio3'] == 1:
        return "3:1"
    else:
        return "No Match"

# Apply the function along the rows (axis=1) to create a new 'ratio1' column
data['ratio1'] = data.apply(calculate_ratio1, axis=1)
data['ratio1'] = data['ratio1'].astype('category')

```

*Run the logistic regression model*

```{python}
model = rsm.model.logistic(
  data = data,
  rvar = "gave",
  lev = 1,
  evar = "ratio1"
)

model.summary()

```

##### This logistic regression results focus on assessing the impact of different match ratios (1:1, 2:1, 3:1, and no match) on the likelihood of making a donation (gave). Let's discuss and interpret each part of the output:

##### Model Overview
- Model Type: Logistic regressionw which models the probability of the outcome variable (gave).
- Response Variable: gave (whether a donation was made, presumably coded as 1 for yes and 0 for no).
- Explanatory Variables: ratio1, categorized into 1:1, 2:1, 3:1, and No Match.

##### Coefficients and Their Interpretation
- Intercept (-3.85): This is the log-odds of giving when all explanatory variables are at their baseline level (likely when ratio1[No Match] is the reference category, based on typical coding). The very negative intercept suggests a very low baseline probability of donating when no match is offered.
- ratio1[2:1] (0.09): Indicates a slight increase in the log odds of donating under the 2:1 match ratio compared to no match, but with a p-value of 0.335, this increase is not statistically significant.
- ratio1[3:1] (0.09): Similar to the 2:1 match, the 3:1 match shows a minimal effect on the log odds of donating and is also not statistically significant (p-value of 0.31).
- ratio1[No Match] (-0.15): This coefficient, if the coding were such that another category were the baseline, would suggest a decrease in the likelihood of donating compared to the baseline. 

##### Statistical Precision
- Standard Errors: Reflect the precision of the estimated coefficients. The larger the standard error, the less precise the estimate. Here, the standard errors are relatively small but not sufficiently so to produce significant results for the 2:1 and 3:1 match ratios.
- Z-values and P-values: These assess the statistical significance of each coefficient. None of the match ratios shows a p-value under the traditional 0.05 threshold for significance, suggesting that there is no strong evidence that either the 2:1 or 3:1 match ratios significantly increase the likelihood of donating compared to no match.

##### Model Fit and Quality
- Pseudo R-squared (McFadden): Very low (0.001), indicating that the model does not explain much of the variance in the response variable beyond the baseline model.
- AUC (0.528): Slightly better than a coin flip, indicating the model has very limited ability to discriminate between those who gave and those who did not based on the match ratio.
- Chi-squared and its p-value (0.011): While the overall model test suggests some level of significance, the lack of significance in individual predictors and the very low explanatory power suggest that match ratios, as modeled, are not strong predictors of donation behavior.

##### Conclusion
- The analysis shows that there is no compelling evidence from this logistic regression model that increasing the match ratio from no match to either a 2:1 or a 3:1 ratio significantly increases the probability of making a donation. This finding could suggest that either the size of the match is not sufficiently motivating to change donor behavior, or that other factors not included in the model are more influential in determining whether individuals donate.




<br><br>

#### I need to calculate the response rate differences between the 1:1 and 2:1 match ratios, and also between the 2:1 and 3:1 match ratios. First, I'll determine these differences directly from the dataset. Then, I'll compute the differences using the fitted coefficients from the previous regression analysis. This dual approach will help me draw conclusions about the effectiveness of various match donation sizes in influencing donation behavior.

*Method 1: Direct Calculation from Data*

```{python}
# Calculate response rates directly from the data
response_rate_1_1 = data[data['ratio'] == 1]['gave'].mean()
response_rate_2_1 = data[data['ratio2'] == 1]['gave'].mean()
response_rate_3_1 = data[data['ratio3'] == 1]['gave'].mean()

# Calculate differences
difference_1_1_to_2_1 = response_rate_2_1 - response_rate_1_1
difference_2_1_to_3_1 = response_rate_3_1 - response_rate_2_1

print(f"Difference in response rate from 1:1 to 2:1: {difference_1_1_to_2_1}")
print(f"Difference in response rate from 2:1 to 3:1: {difference_2_1_to_3_1}")

```



```{python}
# Coefficients from the logistic regression model
coef_1_1 = 0  
coef_2_1 = 0.09  
coef_3_1 = 0.09 

# Calculate differences in log-odds
log_odds_difference_1_1_to_2_1 = coef_2_1 - coef_1_1
log_odds_difference_2_1_to_3_1 = coef_3_1 - coef_2_1

# Convert these log-odds differences to probabilities
probability_difference_1_1_to_2_1 = np.exp(log_odds_difference_1_1_to_2_1) / (1 + np.exp(log_odds_difference_1_1_to_2_1))
probability_difference_2_1_to_3_1 = np.exp(log_odds_difference_2_1_to_3_1) / (1 + np.exp(log_odds_difference_2_1_to_3_1))

print(f"Log-odds difference from 1:1 to 2:1: {log_odds_difference_1_1_to_2_1}")
print(f"Log-odds difference from 2:1 to 3:1: {log_odds_difference_2_1_to_3_1}")
print(f"Probability difference from 1:1 to 2:1: {probability_difference_1_1_to_2_1}")
print(f"Probability difference from 2:1 to 3:1: {probability_difference_2_1_to_3_1}")

```

#### Results Summary:
#### Direct Calculation:
- 1:1 to 2:1: Minimal increase in response rate by approximately 0.19%.
- 2:1 to 3:1: Almost no change in response rate, only about 0.01%.

#### Regression Analysis (Log-Odds and Probabilities):
- 1:1 to 2:1: Log-odds increase of 0.09, translating to a slight probability increase to 52.25%.
- 2:1 to 3:1: No change in log-odds or probability (remains at 50%).

#### Conclusions (Effectiveness of Match Ratios):
- Increasing the match ratio from 1:1 to 2:1 shows a slight positive impact on donation likelihood, though the actual increase is modest.
- No additional benefit is observed when increasing the match ratio from 2:1 to 3:1, suggesting diminishing returns with higher ratios.

#### Implications:
- While a small increase in match ratio to 2:1 might slightly enhance donation rates, further increases (like to 3:1) do not appear to yield significant additional gains. Fundraising strategies might be better served by focusing on other engagement and motivational tactics beyond just increasing match ratios.




<br><br>



### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

#### Now, I'm going to calculate a t-test or conduct a bivariate linear regression to analyze the effect of treatment status on the donation amount. This analysis will help us understand how the treatment influences the actual amounts donated and what implications this might have for understanding donor behavior.

*T-Test*

```{r}
t_test_result <- t.test(amount ~ treatment, data = data)
print(t_test_result)

```

```{python}
lm_result = rsm.model.regress(
  data = data,
  rvar = "amount",
  evar = "treatment"
)

lm_result.summary()


```

#### Welch Two Sample t-test Results:
- T-value: -1.9183 suggests a negative relationship, but in the context of how groups are coded, it indicates that the treatment group (group 1) has a higher mean donation than the control group (group 0).
- P-value: 0.05509, which is just above the conventional threshold of 0.05 for statistical significance. 
- Confidence Interval: Ranges from -0.310 to 0.003. The interval crosses zero, which supports the conclusion that the difference in means is not statistically significant at the 95% confidence level.
- Sample Estimates: Mean donation amount is 0.813 for the control group and 0.966 for the treatment group.

#### Linear Regression (OLS) Results:
- Coefficient for Treatment: 0.15, indicating that, holding all else constant, being in the treatment group is associated with an average increase of 0.15 in donation amount compared to the control group.
- Standard Error: 0.083, leading to a t-value of 1.861.
- P-value for Treatment: 0.063, again marginally above the 0.05 significance level, similar to the t-test.
- R-squared: Close to 0, indicating that the model explains almost none of the variability in donation amounts.

#### Interpretation and Conclusion:
- Both the t-test and the regression analysis suggest that while there appears to be a trend where the treatment group donates more on average than the control group, this difference is not statistically significant at the conventional 5% level. However, the p-values are quite close to the threshold, which might suggest practical significance if not statistical.

#### Practical Implications: 
- Even though the differences are not statistically significant, the trend towards higher donations in the treatment group could be of interest in practical terms. For example, in large-scale fundraising operations, even small increases in average donations can translate to substantial total increases.

#### Statistical Considerations: 
- The closeness of the p-values to the threshold of significance suggests that with a slightly larger sample size or a slightly stronger effect, the results might become statistically significant.



<br><br>

#### Now I'm going  to refine the previous analysis by limiting the data to individuals who actually made a donation. Then, I'll repeat the t-test or bivariate linear regression to assess the impact of treatment status on the donation amount among this specific group. This focused regression will help us explore how much donors contribute, conditional on their decision to donate a positive amount. I'll interpret the regression coefficients to extract insights and evaluate whether the treatment coefficient can be considered to have a causal interpretation.


*Data Preparation*
```{r}
donors <- data %>%
  filter(gave == 1 & amount > 0)

```

```{python, include = FALSE}
donors = data[(data['gave'] == 1) & (data['amount'] > 0)]

```


*T-Test*

```{r}
t_test_result <- t.test(amount ~ treatment, data = donors)
print(t_test_result)

```
*Regression Model*

```{python}
lm_result_doners = rsm.model.regress(
  data = donors,
  rvar = "amount",
  evar = "treatment"
)

lm_result_doners.summary()

```

### T-Test and Linear Regression Results (Limited to Donors):

#### T-Test Results:
- P-value: 0.05509, indicating that the difference in donation amounts between the treatment and control groups among donors is nearly significant at the conventional 0.05 level.
- Confidence Interval: Ranges from -0.311 to 0.003, including zero, which supports the lack of significant difference.

#### Linear Regression Results:
- Treatment Coefficient: 0.15, suggesting that being in the treatment group is associated with an average increase in donation amount by $0.15. 
- Intercept: The average donation amount in the control group is $0.81, statistically significant as indicated by the p-value < .001.

#### Interpretation and Conclusion:
- Effect of Treatment: The results imply that while there is a trend towards higher donations among those treated, this is not strong enough to be statistically significant. The average increase of $0.15 in the donation amount due to treatment, although not significant, suggests a potential positive influence of the treatment on donor behavior.

- Causal Interpretation: Given the experimental design, if the treatment assignment was indeed randomized, this regression among donors could still suggest a causal interpretation—treatment might cause a slight increase in donation amounts. 



<br><br>

#### Now I'm going to create two histograms, one for the treatment group and one for the control group, displaying the distribution of donation amounts among those who have actually donated. In each plot, I'll include a red vertical bar or a similar annotation to mark the sample average. This visualization will help illustrate how donation behaviors differ between the two groups and highlight the average donation amount for each.

```{r}
donors <- data[data$amount > 0, ]

treatment_data <- donors[donors$treatment == 1, ]
control_data <- donors[donors$treatment == 0, ]

# Treatment Group
p1 <- ggplot(treatment_data, aes(x = amount)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  geom_vline(aes(xintercept = mean(amount)), color = "red", linetype = "dashed", size = 1) +
  ggtitle("Treatment Group Donation Amounts") +
  xlab("Donation Amount") +
  ylab("Frequency") +
  theme_classic()

# Control Group
p2 <- ggplot(control_data, aes(x = amount)) +
  geom_histogram(bins = 30, fill = "lightgreen", color = "black") +
  geom_vline(aes(xintercept = mean(amount)), color = "red", linetype = "dashed", size = 1) +
  ggtitle("Control Group Donation Amounts") +
  xlab("Donation Amount") +
  ylab("Frequency") +
  theme_classic()

print(p1)
print(p2)

```



#### Treatment Group Histogram:
- Distribution: The frequency of donations is skewed to the right, where smaller donations are more common.
- Average Donation: The red line here also shows the average donation amount, which again is on the lower end, confirming that most donations are smaller.

#### Control Group Histogram:
- Distribution: The frequency of donations is skewed to the right, meaning most donations are small amounts, with fewer large donations.
- Average Donation: The red line indicates where the average donation amount falls, which is relatively low compared to the full range of donations, affirming the skewness towards smaller amounts.

#### Simple Interpretation:
- Both groups, on average, tend to give smaller amounts, with a few larger donations being less common. 



<br><br>



## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.

Further suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.

<br><br>

### Law of Large Numbers

#### I'll simulate 100,000 draws from the control distribution and 10,000 draws from the treatment distribution. Then, I’ll calculate a vector of 10,000 differences between these distributions. I’ll plot the cumulative average of this vector of differences. This visualization will allow us to observe whether the cumulative average converges towards the true difference in means between the treatment and control groups, and I'll provide commentary on these findings


```{r}
# Calculate the mean and standard deviation for treatment and control
control_mean <- mean(data$control, na.rm = TRUE)
control_sd <- sd(data$control, na.rm = TRUE)
treatment_mean <- mean(data$treatment, na.rm = TRUE)
treatment_sd <- sd(data$treatment, na.rm = TRUE)

# Simulate 100,000 draws from the control distribution and 10,000 from the treatment
set.seed(123) 
control_draws <- rnorm(100000, control_mean, control_sd)
treatment_draws <- rnorm(10000, treatment_mean, treatment_sd)

# Calculate the differences
differences <- sapply(1:10000, function(i) treatment_draws[i] - sample(control_draws, 1))

# Calculate cumulative average
cumulative_avg <- cumsum(differences) / seq_along(differences)


df <- data.frame(Draw = 1:10000, CumulativeAverage = cumulative_avg)
p <- ggplot2::ggplot(df, aes(x = Draw, y = CumulativeAverage)) +
  ggplot2::geom_line() +
  ggplot2::geom_hline(yintercept = mean(differences), color = 'red', linetype = 'dashed') +
  ggplot2::labs(title = 'Cumulative Average Difference Between Treatment and Control',
       x = 'Number of Draws',
       y = 'Cumulative Average Difference') +
  ggplot2::theme_classic()

print(p)

```

#### This plot shows the cumulative average difference in donation amounts between the treatment and control groups across a number of simulated draws. Here’s a simple explanation of what it represents:

- Y Axis (Cumulative Average Difference): This axis shows the average difference in donations between the treatment and control groups, calculated cumulatively.
- X Axis (Number of Draws): This represents the number of simulated differences that have been averaged together at each point on the plot.
- Red Dashed Line: This line represents the true difference in means between the treatment and control groups as calculated from the simulated data.
- Black Line: This represents the cumulative average of the differences with each additional draw.
At the beginning, the cumulative average fluctuates significantly due to the small sample size. However, as more draws are added (moving right along the horizontal axis), the cumulative average begins to stabilize and converges toward the true difference indicated by the red dashed line.

- The convergence of the black line toward the red dashed line suggests that with enough data, the sample estimate (cumulative average of the simulated differences) approaches the actual difference between the groups. This illustrates the law of large numbers, which states that as the number of trials increases, the average of the results should get closer to the expected value (the true difference in this case).


<br><br>

### Central Limit Theorem

#### Finally, I'm going to produce four histograms, corresponding to sample sizes of 50, 200, 500, and 1000. For each histogram, I’ll start by taking the specified number of draws from both the control and treatment distributions. I'll calculate the average difference between these draws. This process will be repeated 999 times to accumulate 1000 average differences. 

```{r}
create_hist_data <- function(data, sample_size, num_samples) {
  replicate(num_samples, {
    sample_control <- sample(data$control, sample_size, replace = TRUE)
    sample_treatment <- sample(data$treatment, sample_size, replace = TRUE)
    mean(sample_treatment) - mean(sample_control)
  })
}

# Create histogram data for different sample sizes
set.seed(123)
hist_data_50 <- create_hist_data(data, 50, 1000)
hist_data_200 <- create_hist_data(data, 200, 1000)
hist_data_500 <- create_hist_data(data, 500, 1000)
hist_data_1000 <- create_hist_data(data, 1000, 1000)

# Combine all histogram data into a single dataframe
hist_data <- data.frame(
  AverageDifference = c(hist_data_50, hist_data_200, hist_data_500, hist_data_1000),
  SampleSize = factor(rep(c(50, 200, 500, 1000), each = 1000))
)


ggplot2::ggplot(hist_data, aes(x = AverageDifference, fill = SampleSize)) +
  ggplot2::geom_histogram(data = subset(hist_data, SampleSize %in% c(50, 200)), 
                 bins = 30, position = 'identity', alpha = 0.3) +
  ggplot2::geom_histogram(data = subset(hist_data, SampleSize %in% c(500, 1000)), 
                 bins = 30, position = 'identity', alpha = 0.3) +
  ggplot2::scale_fill_manual(values = c("red", "blue", "green", "purple")) +
  ggplot2::geom_vline(xintercept = 0, color = "red", linetype = "dashed") +
  ggplot2::labs(x = "Average Difference", y = "Frequency", fill = "Sample Size") +
  ggplot2::theme_classic() +
  ggplot2::theme(legend.position = "bottom") +
  ggplot2::coord_flip()


```

*Plot Interpretation*
- Sample Size 50 (Red): The distribution is wide, suggesting that smaller sample sizes yield more variability in the average difference. The average differences are spread out, which indicates less precision in the estimate of the true effect.

- Sample Size 200 (Blue): The distribution begins to narrow compared to the sample size of 50. This indicates that increasing the sample size reduces variability and provides a more precise estimate of the average difference.

- Sample Size 500 (Green): The distribution narrows even further, showing even greater precision in the estimate of the average difference. The height of the distribution is increasing, indicating that more sample averages are concentrated around a specific range.

- Sample Size 1000 (Purple): This distribution is the narrowest, suggesting that the largest sample size provides the most precise estimate of the average difference. The tall and narrow shape indicates that the sample averages are highly concentrated, and the variability of the difference estimate is the lowest.

<br><br>

## Conclusion
#### Throughout this analysis, I tackled into the efficacy of various fundraising strategies, employing rigorous statistical techniques to explore the dynamics between control and treatment groups within a charitable donation context. The investigation here revealed that while increasing the match ratio has a slight positive impact on donation rates, this effect does not escalate with higher ratios, suggesting a point of diminishing returns. Additionally, the findings suggest that treatment may modestly increase donation amounts, albeit not at a statistically significant level. Simulations further demonstrated the Law of Large Numbers and the Central Limit Theorem, reinforcing the reliability of our statistical inferences. Ultimately, this analysis provides valuable insights into donor behavior, indicating that while strategic tweaks can enhance fundraising outcomes, there is a threshold beyond which their effectiveness plateaus. This study's nuanced conclusions contribute to optimizing fundraising techniques, ensuring resources are directed towards the most impactful strategies.




